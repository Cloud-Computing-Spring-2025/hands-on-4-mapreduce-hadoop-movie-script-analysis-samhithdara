# Hands-on 2: Analyzing Movie Script Dialogue Using Hadoop MapReduce

This hands-on activity is designed to extend your understanding of Hadoop MapReduce by analyzing a dataset of movie script dialogues. You will implement MapReduce jobs to extract and analyze:
1. The most frequently spoken words by characters.
2. Total dialogue length per character.
3. Unique words used by each character.

## Objectives

By completing this hands-on activity, students will:

1. **Enhance Text Processing Skills:** Learn to process and analyze text data to extract meaningful insights using Hadoop MapReduce.
2. **Develop Advanced MapReduce Jobs:** Implement more complex MapReduce jobs to perform tasks like finding the most frequently used words, calculating dialogue lengths, and extracting unique words by characters.
3. **Deploy and Run a Hadoop Cluster with Docker:** Learn how to deploy a Hadoop cluster using Docker and run MapReduce jobs on it.
4. **Submit and Manage Code Using GitHub:** Develop skills in managing code and submitting assignments via GitHub.

---

## Setup and Execution

### 1. **Fork the GitHub Repository**

- First, accept the GitHub Classroom invitation and fork the assignment repository to your own GitHub account.
- Once you’ve forked the repo, open the repository in **GitHub Codespaces** to begin working on the assignment.

---

### 2. **Start the Hadoop Cluster Using Docker Compose**

The repository contains a `docker-compose.yml` file that configures a Hadoop cluster. Run the following command in the GitHub Codespaces terminal to start the cluster:

```bash
docker-compose up -d
```

This command will spin up the necessary Hadoop components (ResourceManager, NodeManager, etc.) inside Docker containers.

---

### 3. **Build the Java Code with Maven**

After starting the cluster, use Maven to build the Java MapReduce code for the movie script analysis. In the terminal, execute the following command to compile and build the project:

```bash
mvn clean install
```

This command will generate a JAR file in the `target/` directory, which contains your MapReduce code.

---

### 4. **Prepare Input Data Files**

1. The input movie script dialogues dataset is located in the `input/` folder of the repository. Ensure that this file (`movie_dialogues.txt`) is present in the `input/` directory.

---

### 5. **Move the JAR and Input Files to the Docker Container**

#### **5.1 Move the JAR File to the Container**

Copy the built JAR file to the ResourceManager container. Run this command:

**Note**: Replace `<your-jar-file>` with the actual name of the JAR file generated by Maven.

```bash
docker cp target/<your-jar-file>.jar resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

#### **5.2 Move the Input File to the Container**

Next, copy the movie script dialogues dataset to the ResourceManager container:

```bash
docker cp input/movie_dialogues.txt resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

---

### 6. **Connect to the ResourceManager Container**

To run the Hadoop commands, you'll need to connect to the ResourceManager container:

```bash
docker exec -it resourcemanager /bin/bash
```

Once inside the container, navigate to the Hadoop directory where your files were copied:

```bash
cd /opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

---

### 7. **Set Up HDFS for Input File**

To run the MapReduce job, the input file needs to be stored in Hadoop’s distributed file system (HDFS).

#### **7.1 Create Directories in HDFS**

Create a directory in HDFS for the input file:

```bash
hadoop fs -mkdir -p /input/movie_scripts
```

#### **7.2 Upload the Input File to HDFS**

Upload the movie script dialogues file to HDFS:

```bash
hadoop fs -put movie_dialogues.txt /input/movie_scripts/
```

---

### 8. **Execute the Movie Script Analysis MapReduce Jobs**

Now you are ready to run your MapReduce job for movie script analysis. This job will consist of three tasks:
1. Most Frequent Words by Character
2. Dialogue Length Analysis
3. Unique Words by Character

Run the job using the following command:

**Note**: Replace `<your-jar-file>` with the actual name of the JAR file generated by Maven.

```bash
hadoop jar <your-jar-file>.jar com.movie.script.analysis.MovieScriptAnalysis /input/movie_scripts/movie_dialogues.txt /output
```

This command will execute the MapReduce job with the movie script dialogues as the input and store the results in the `/output` directory in HDFS.

---

### 9. **View the Output of the MapReduce Job**

**Note**: The output will be stored in multiple directories (one for each task). You can view the output files using the following commands:

#### **9.1 List the Output Directories**

```bash
hadoop fs -ls /output
```

#### **9.2 View the Output Files for Each Task**

- **Task 1: Most Frequent Words by Character**
```bash
hadoop fs -cat /output/task1/part-r-00000
```

- **Task 2: Dialogue Length Analysis**
```bash
hadoop fs -cat /output/task2/part-r-00000
```

- **Task 3: Unique Words by Character**
```bash
hadoop fs -cat /output/task3/part-r-00000
```

These commands will display the results for each analysis task.

---

### 10. **Copy Output from HDFS to Local OS**

Once you have verified the results, copy the output from HDFS to your local file system.

#### **10.1 Copy Output from HDFS**

Use the following command to copy the output from HDFS to the Hadoop directory:

```bash
hadoop fs -get /output /opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

#### **10.2 Copy Output from the Container to Your Local Machine**

Now, exit the ResourceManager container:

```bash
exit
```

Next, copy the output files from the Docker container to your GitHub Codespaces environment:

```bash
docker cp resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/output/ ./output/
```

---

### 11. **Submit Your Code and Output**

#### **11.1 Push Your Code and Output to GitHub**

Commit your changes, including the output from the MapReduce job, and push them to your GitHub repository:

```bash
git add .
git commit -m "Completed Movie Script Analysis Assignment"
git push origin main
```

#### **11.2 Submit the Assignment on GitHub Classroom**

Once you've pushed your code, go to GitHub Classroom and ensure your repository is submitted for the assignment. Make sure that the following are included:

1. The JAR file with your MapReduce job.
2. The input file (`movie_dialogues.txt`).
3. The output files from your MapReduce job.
4. The one-page report documenting the steps you followed, any challenges faced, and your observations.

---

### **Grading Criteria:**

1. **Correct Implementation of MapReduce Jobs:** The MapReduce jobs must correctly extract and analyze data as per the three tasks described.
2. **Proper Use of Hadoop and Docker:** Your solution must successfully deploy a Hadoop cluster using Docker and correctly manage input/output files using HDFS.
3. **Submission of Code and Output:** The correct output should be produced and submitted via GitHub, along with the code and a brief report.
4. **Report:** A clear one-page report summarizing your setup, challenges, and observations.

---

Here’s a structured project report based on your Hadoop MapReduce job for finding the top 10 most frequent words in a movie script.  

---

# **Movie Script Word Frequency Analysis using Hadoop MapReduce**  
Here’s a structured project report covering all three tasks combined:  

---

# **Movie Script Analysis using Hadoop MapReduce**  

## **1. Project Overview**  
This project analyzes movie scripts using Hadoop MapReduce by performing three key tasks:  
1. **Word Frequency Analysis** – Identifies the most frequently spoken words in the script.  
2. **Dialogue Length Calculation** – Computes the total number of words spoken by each character.  
3. **Unique Words Per Character** – Determines the unique words spoken by each character.  

By leveraging Hadoop’s distributed processing, the project efficiently processes large scripts and extracts valuable insights.  

---

## **2. Approach and Implementation**  

### **Task 1: Word Frequency Analysis**  
#### **Mapper (CharacterWordMapper.java)**  
- Reads each line of the script, tokenizes it into words, and associates each word with a count of `1`.  
- Outputs key-value pairs in the format `<word, 1>`.  

#### **Reducer (CharacterWordReducer.java)**  
- Aggregates word counts to determine their total occurrences in the script along with maintaing top 10.  
- Outputs key-value pairs in the format `<word, total_count>`.  

---

### **Task 2: Dialogue Length Calculation**  
#### **Mapper (DialogueLengthMapper.java)**  
- Extracts the character name and the number of words spoken in their dialogue.  
- Outputs key-value pairs in the format `<character, word_count>`.  

#### **Reducer (DialogueLengthReducer.java)**  
- Sums up the word counts for each character to determine the total dialogue length.  
- Outputs key-value pairs in the format `<character, total_word_count>`.  

---

### **Task 3: Unique Words Per Character**  
#### **Mapper (UniqueWordsMapper.java)**  
- Associates each unique word with the character who spoke it.  
- Outputs key-value pairs in the format `<character, word>`.  

#### **Reducer (UniqueWordsReducer.java)**  
- Collects unique words spoken by each character.  
- Outputs key-value pairs in the format `<character, unique_words_list>`.  

---

## **3. Execution Steps**  
Followed steps mentioned above
---

## **4. Challenges Faced & Solutions**  

Had issue in finding the top 10 values later able to resolve it using the new function

---

## **5. Sample Input and Output**  

### **Sample Input (Movie Script Snippet)**
```txt
CHARACTER_A: Hello there! Welcome to the movie.
CHARACTER_B: Movies are great. Hello again!
CHARACTER_A: Yes, movies are amazing.
```

### **Output for Task 1: Word Frequency Analysis**  
```txt
hello    2  
there    1  
welcome  1  
to       1  
movie    1  
movies   2  
are      2  
great    1  
again    1  
yes      1  
amazing  1  
```

### **Output for Task 2: Dialogue Length Calculation**  
```txt
CHARACTER_A    7  
CHARACTER_B    5  
```

### **Output for Task 3: Unique Words Per Character**  
```txt
CHARACTER_A    hello, there, welcome, to, movie, yes, amazing  
CHARACTER_B    movies, are, great, hello, again  
```


This concludes the instructions for the hands-on activity. If you encounter any issues, feel free to reach out during office hours or post your queries in the course discussion forum.

Good luck, and happy coding!

---
